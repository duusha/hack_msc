{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozYEOvT809so",
        "outputId": "b9d6e101-3442-4d65-b1f0-4b7692826688"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-11 12:29:25--  https://docs.google.com/uc?export=download&id=18Wx4PmuM3A4L3cpeEzM71WZf4HybVJ3o\n",
            "Resolving docs.google.com (docs.google.com)... 173.194.195.138, 173.194.195.113, 173.194.195.102, ...\n",
            "Connecting to docs.google.com (docs.google.com)|173.194.195.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=18Wx4PmuM3A4L3cpeEzM71WZf4HybVJ3o&export=download [following]\n",
            "--2024-06-11 12:29:25--  https://drive.usercontent.google.com/download?id=18Wx4PmuM3A4L3cpeEzM71WZf4HybVJ3o&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 108.177.121.132, 2607:f8b0:4001:c19::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|108.177.121.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 182842 (179K) [application/octet-stream]\n",
            "Saving to: ‘hack.zip’\n",
            "\n",
            "hack.zip            100%[===================>] 178.56K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-06-11 12:29:26 (66.3 MB/s) - ‘hack.zip’ saved [182842/182842]\n",
            "\n",
            "--2024-06-11 12:29:27--  https://docs.google.com/uc?export=download&id=1bCI9KbpJCDURD3v8D92-oEWTgqOpiIh2\n",
            "Resolving docs.google.com (docs.google.com)... 173.194.195.138, 173.194.195.113, 173.194.195.102, ...\n",
            "Connecting to docs.google.com (docs.google.com)|173.194.195.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1bCI9KbpJCDURD3v8D92-oEWTgqOpiIh2&export=download [following]\n",
            "--2024-06-11 12:29:27--  https://drive.usercontent.google.com/download?id=1bCI9KbpJCDURD3v8D92-oEWTgqOpiIh2&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 108.177.121.132, 2607:f8b0:4001:c19::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|108.177.121.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12932 (13K) [application/octet-stream]\n",
            "Saving to: ‘model.zip’\n",
            "\n",
            "model.zip           100%[===================>]  12.63K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-06-11 12:29:28 (46.3 MB/s) - ‘model.zip’ saved [12932/12932]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "file_id = '18Wx4PmuM3A4L3cpeEzM71WZf4HybVJ3o'  # замените на ваш идентификатор файла\n",
        "file_name = 'hack.zip'  # замените на желаемое имя файла и расширение\n",
        "\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id={file_id}' -O {file_name}\n",
        "\n",
        "# https://drive.google.com/file/d//view?usp=sharing\n",
        "file_id = '1bCI9KbpJCDURD3v8D92-oEWTgqOpiIh2'  # замените на ваш идентификатор файла\n",
        "file_name = 'model.zip'  # замените на желаемое имя файла и расширение\n",
        "\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id={file_id}' -O {file_name}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip hack.zip\n",
        "!unzip model.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AC5bSFTI1RhU",
        "outputId": "449e9388-efe5-4290-b092-ea571931d0f6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  hack.zip\n",
            "  inflating: 9. ДЗМ/Количество исследований за месяц (для проверки).xlsx  \n",
            "  inflating: 9. ДЗМ/Количество исследований по неделям (для реализации).xlsx  \n",
            "  inflating: 9. ДЗМ/Нормативы РЦ.xlsx  \n",
            "  inflating: 9. ДЗМ/Пример табеля с количеством врачей в разрезе модальностей и доп модальностей.xlsx  \n",
            "  inflating: 9. ДЗМ/Шаблон для заполнения проверки по прогнозу за Февраль.xlsx  \n",
            "Archive:  model.zip\n",
            "   creating: model/\n",
            "  inflating: model/last.pt           \n",
            "  inflating: model/best.pt           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: создай пять dataframe по каждому файлу xlsx которые лежат в 9. ДЗМ\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Создаем словарь для хранения датафреймов\n",
        "df_dict = {}\n",
        "\n",
        "# Перебираем файлы в папке 9. ДЗМ\n",
        "for file_name in os.listdir('9. ДЗМ'):\n",
        "  # Проверяем, что файл имеет расширение xlsx\n",
        "  if file_name.endswith('.xlsx'):\n",
        "    # Читаем файл xlsx и сохраняем его в словаре\n",
        "    df_dict[file_name] = pd.read_excel(os.path.join('9. ДЗМ', file_name))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lNPDOeR81VKD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataframe, window_size, prev_weeks):\n",
        "        self.data = dataframe\n",
        "        self.window_size = window_size\n",
        "        self.prev_weeks = prev_weeks\n",
        "\n",
        "        # Удаление строк с NaN значениями (в конце)\n",
        "        self.data.dropna(inplace=True)\n",
        "\n",
        "        # Создание входных и выходных переменных\n",
        "        self.X, self.y = self.create_sequences_old()\n",
        "\n",
        "    def create_sequences_old(self):\n",
        "        X, y = [], []\n",
        "        for i in range(len(self.data) - self.window_size):\n",
        "            X.append(self.data.iloc[i:i+self.window_size, :12].values)\n",
        "            y.append(self.data.iloc[i+self.window_size, 2:12].values)\n",
        "        return np.array(X), np.array(y)\n",
        "\n",
        "    def create_sequences(self):\n",
        "        X, y = [], []\n",
        "        for i in range(52, len(self.data) - self.window_size - 2):\n",
        "            print(i + self.window_size - 1 - (52 + self.prev_weeks // 2 + 1), i + self.window_size - 1 - (52 - self.prev_weeks // 2))\n",
        "            _1 = self.data.iloc[i:i+self.window_size, :12].values\n",
        "            _2 = self.data.iloc[i + self.window_size - (52 + self.prev_weeks // 2): i + self.window_size - (52 - self.prev_weeks // 2) , :12].values\n",
        "            print(_2.shape)\n",
        "            print(_1.shape)\n",
        "            X.append(np.concatenate((_1, _2), axis=0))\n",
        "            # _1 = self.data.iloc[i+self.window_size-1, :2]\n",
        "            # _2 = self.data.iloc[i+self.window_size-1, 12:].values\n",
        "            # y.append(np.concatenate((_1, _2), axis=0))\n",
        "            y.append(self.data.iloc[i+self.window_size-1, 12:].values)\n",
        "        return np.array(X), np.array(y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        X = torch.tensor(self.X[idx], dtype=torch.float32)\n",
        "        y = torch.tensor(self.y[idx], dtype=torch.float32)\n",
        "        return X, y\n",
        "    def append(self,x, y):\n",
        "      self.X = np.append(self.X, x, axis=0)\n",
        "      self.y = np.append(self.y, y.detach().numpy(), axis = 0)\n",
        "\n",
        "window_size = 5\n",
        "prev_weeks = 5\n"
      ],
      "metadata": {
        "id": "P62iAo8i7Evd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "uqVDUNwR8vjb",
        "outputId": "7c2caaba-b6da-44e9-87e2-24a27602d9c4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'dataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-4d78676a1a5f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "def cosine_distance(tensor1, tensor2):\n",
        "    \"\"\"\n",
        "    Вычисляет косинусное расстояние между двумя тензорами.\n",
        "\n",
        "    Args:\n",
        "    tensor1 (torch.Tensor): Первый тензор.\n",
        "    tensor2 (torch.Tensor): Второй тензор.\n",
        "\n",
        "    Returns:\n",
        "    float: Косинусное расстояние между двумя тензорами.\n",
        "    \"\"\"\n",
        "    cos = nn.CosineSimilarity(dim=0, eps=1e-6)\n",
        "    return 1 - cos(tensor1, tensor2)\n",
        "\n",
        "\n",
        "class CustomHuberLoss(nn.Module):\n",
        "    def __init__(self, delta=1.0):\n",
        "        super(CustomHuberLoss, self).__init__()\n",
        "        self.delta = delta\n",
        "\n",
        "    def forward(self, outputs, targets):\n",
        "        huber_loss = torch.where(\n",
        "            torch.abs(outputs - targets) < self.delta,\n",
        "            0.5 * (outputs - targets) ** 2,\n",
        "            self.delta * (torch.abs(outputs - targets) - 0.5 * self.delta)\n",
        "        )\n",
        "        penalty = torch.sum(torch.relu(-outputs))  # штраф за отрицательные значения\n",
        "        return torch.mean(huber_loss) + penalty\n",
        "\n",
        "# Определение модели нейронной сети\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "def custom_loss(outputs, targets):\n",
        "    mse_loss = nn.MSELoss()(outputs, targets)\n",
        "    penalty = torch.sum(torch.relu(-outputs)) * 2 # штраф за отрицательные значения\n",
        "    return mse_loss + penalty\n",
        "\n",
        "\n",
        "def predict_n_weeks(model, dataset, n_weeks):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "\n",
        "    # Берем последние window_size недель для инициализации\n",
        "    # last_x = dataset.X[-1].reshape(1, -1, 10)\n",
        "    last_x = np.expand_dims(dataset.X[-1], axis=0)\n",
        "    # Получаем последний год и номер недели\n",
        "    last_year = dataset.data['Год'].iloc[-1]\n",
        "    last_week = dataset.data['Номер недели'].iloc[-1]\n",
        "\n",
        "    for _ in range(n_weeks):\n",
        "        # Преобразуем last_x в нужную форму и делаем предсказание\n",
        "        last_x_tensor = torch.tensor(last_x, dtype=torch.float32).view(1, -1)\n",
        "        with torch.no_grad():\n",
        "            pred = model(last_x_tensor).detach().numpy().reshape(1, -1)\n",
        "\n",
        "        # Добавляем предсказание в список\n",
        "        predictions.append(pred)\n",
        "\n",
        "        # Обновляем неделю и год\n",
        "        next_week = last_week + 1\n",
        "        next_year = last_year\n",
        "        if next_week > 52:  # Переход на следующий год\n",
        "            next_week = 1\n",
        "            next_year += 1\n",
        "        new_row = np.array([[next_year, next_week] + list(pred[0])])\n",
        "        last_x = np.append(last_x[:, 1:, :], new_row.reshape(1, 1, -1), axis=1)\n",
        "\n",
        "        # Обновляем год и неделю для следующей итерации\n",
        "        last_year = next_year\n",
        "        last_week = next_week\n",
        "\n",
        "    return np.array(predictions).reshape(n_weeks, -1)\n",
        "\n",
        "df = df_dict[\"Количество исследований по неделям (для реализации).xlsx\"].copy()\n",
        "dataset = CustomDataset(df, window_size=window_size, prev_weeks=prev_weeks)\n",
        "\n",
        "input_size = window_size * 12  # 10 наблюдений за каждую неделю в окне\n",
        "hidden_size = 20\n",
        "output_size = 10  # количество целевых переменных\n",
        "model = SimpleNN(input_size, hidden_size, output_size)\n",
        "criterion = CustomHuberLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "model.load_state_dict(torch.load(\"model/best.pt\"))\n",
        "model.eval()\n",
        "pred_num_week = 3\n",
        "result = predict_n_weeks(model, dataset, pred_num_week)\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCjploi2-GAN",
        "outputId": "931d1a4b-7233-4ca0-82af-ffcb908b1fff"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2181.3127   4728.655     669.71173   201.12605 17005.715     930.73175\n",
            "    577.8397    387.1721  79720.7      6291.27   ]\n",
            " [ 2424.427    3227.1257    622.79974   325.45993 17975.773    1538.9012\n",
            "    996.94946   103.80257 80631.39     8444.229  ]\n",
            " [ 1826.709    4062.5608    545.57007    86.00709 14317.014     444.2146\n",
            "    308.38666   402.66788 69180.73     1779.6624 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LMUoB-9uAnlH"
      },
      "execution_count": 55,
      "outputs": []
    }
  ]
}